{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATE TWITTER TROLL DETECTION USING TRANSFORMERS\n",
    "\n",
    "## REPO STRUCTURE\n",
    "\n",
    "### 1. DATA FOLDER\n",
    "\n",
    "* 5 CSV files for notebooks in this series. Note that raw troll tweet files from Twitter are not included here.\n",
    "\n",
    "### 2. NOTEBOOKS FOLDER\n",
    "\n",
    "* Notebooks 1.0 - 1.2: Data collection, cleaning and preparation. Optional if you just want to experiment with the final dataset.\n",
    "\n",
    "* Notebooks 2.0 - 2.1: Fine tuning distilbert with custom dataset and detailed testing with unseen validation dataset, as well as a fresh dataset with state troll tweets from Iran.\n",
    "\n",
    "* * Notebook 3.0 - 3.1: Create and test optimised logistic regression and XGB models against datasets used to assess fine tuned Distilbert model.\n",
    "\n",
    "\n",
    "### 3. APP FOLDER\n",
    "\n",
    "* app.py + folders for \"static\" and \"template: simple app for use on a local machine to demonstrate how a state troll tweet detector can be used in deployment. Unfortunately free hosting accounts can't accomodate the disk size required for pytorch and the fine tuned model, so I've not deployed this online. \n",
    "\n",
    "\n",
    "### 4. TROLL_DETECT FOLDER\n",
    "\n",
    "* Fine tuned Distilbert model from Colab notebook2.0. Too big for Github, download [here](https://www.dropbox.com/sh/90h7ymog2oi5yn7/AACTuxmMTcso6aMxSmSiD8AVa) from Dropbox instead.\n",
    "\n",
    "### 5. PKL FOLDER\n",
    "\n",
    "* Pickled logistic regression model from notebook3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1C: SPLIT DATASETS FOR TRAINING AND VALIDATION\n",
    "\n",
    "Most tutorials out there tend to lump the data preparation section together with the fine tuning part. I prefer to keep them separate for clarity, so that I'd know what's in various sections of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepared in notebook1.0, avail in repo \n",
    "troll = pd.read_csv(\"../data/troll_50k.csv\")\n",
    "\n",
    "# prepared in notebook1.1, avail in repo \n",
    "real = pd.read_csv(\"../data/real_50k.csv\")\n",
    "    \n",
    "tweets = pd.concat([troll, real])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweetid              0\n",
       "user_display_name    0\n",
       "tweet_text           0\n",
       "clean_text           0\n",
       "troll_or_not         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>user_display_name</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>troll_or_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1245883557362282497</td>\n",
       "      <td>85c9M6CDZxgBwoEye0rF12ZBgGl3xvz6Bnbvhp7MUKI=</td>\n",
       "      <td>having each tiny wish come true, or having som...</td>\n",
       "      <td>having each tiny wish come true or having some...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>961577921461866496</td>\n",
       "      <td>曲剑明</td>\n",
       "      <td>＠null It is 12:25 UTC now</td>\n",
       "      <td>null It is UTC now</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>941616158075211776</td>\n",
       "      <td>IFL1E0m0SRX2cdOtuLFV7xKtnBgxagKzNgkuGFvNtvs=</td>\n",
       "      <td>British number two Bedene to switch back to Sl...</td>\n",
       "      <td>British number two Bedene to switch back to Sl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>850414479976345600</td>\n",
       "      <td>Klausv</td>\n",
       "      <td>kalamitykait Thanks for bearing with us - you ...</td>\n",
       "      <td>kalamitykait Thanks for bearing with us you sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>960784360071925760</td>\n",
       "      <td>曲剑明</td>\n",
       "      <td>＠null It is 08:56 CET now</td>\n",
       "      <td>null It is CET now</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               tweetid                             user_display_name  \\\n",
       "0  1245883557362282497  85c9M6CDZxgBwoEye0rF12ZBgGl3xvz6Bnbvhp7MUKI=   \n",
       "1   961577921461866496                                           曲剑明   \n",
       "2   941616158075211776  IFL1E0m0SRX2cdOtuLFV7xKtnBgxagKzNgkuGFvNtvs=   \n",
       "3   850414479976345600                                        Klausv   \n",
       "4   960784360071925760                                           曲剑明   \n",
       "\n",
       "                                          tweet_text  \\\n",
       "0  having each tiny wish come true, or having som...   \n",
       "1                          ＠null It is 12:25 UTC now   \n",
       "2  British number two Bedene to switch back to Sl...   \n",
       "3  kalamitykait Thanks for bearing with us - you ...   \n",
       "4                          ＠null It is 08:56 CET now   \n",
       "\n",
       "                                          clean_text  troll_or_not  \n",
       "0  having each tiny wish come true or having some...             1  \n",
       "1                                 null It is UTC now             1  \n",
       "2  British number two Bedene to switch back to Sl...             1  \n",
       "3  kalamitykait Thanks for bearing with us you sh...             1  \n",
       "4                                 null It is CET now             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: CREATE VALIDATION SET\n",
    "\n",
    "We'll keep to a split of 70:20:10 for training, testing and validation. Here we'll split off 10% of the dataset - 10k rows - and keep them aside for testing the fine tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = tweets.sample(n=10000, random_state=42, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    5061\n",
       "0    4939\n",
       "Name: troll_or_not, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not an exact 50-50 split, but good enough\n",
    "\n",
    "validate[\"troll_or_not\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is included in the repo\n",
    "# avail here: https://github.com/chuachinhon/transformers_state_trolls_cch/blob/master/data/validate.csv\n",
    "\n",
    "'''\n",
    "validate.to_csv(\n",
    "    \"../data/validate.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8\",\n",
    "    quoting=csv.QUOTE_NONNUMERIC,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2: CREATE MAIN TRAINING SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tweetids are unique, so removing these ids from the main dataset\n",
    "# will give us the raw training dataset, which will then be further split into train-test sets prior to fine tuning\n",
    "\n",
    "validate_id = validate['tweetid'].values\n",
    "\n",
    "train_raw = tweets[~tweets['tweetid'].isin(validate_id)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    45009\n",
       "1    44939\n",
       "Name: troll_or_not, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw['troll_or_not'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is included in the repo\n",
    "# avail here: https://github.com/chuachinhon/transformers_state_trolls_cch/blob/master/data/train_raw.csv\n",
    "\n",
    "'''\n",
    "train_raw.to_csv(\n",
    "    \"../data/train_raw.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8\",\n",
    "    quoting=csv.QUOTE_NONNUMERIC,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
