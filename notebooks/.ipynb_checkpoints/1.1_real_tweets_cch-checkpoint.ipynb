{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATE TWITTER TROLL DETECTION USING TRANSFORMERS\n",
    "\n",
    "## REPO STRUCTURE\n",
    "\n",
    "### 1. DATA FOLDER\n",
    "\n",
    "* 5 CSV files for notebooks in this series. Note that raw troll tweet files from Twitter are not included here.\n",
    "\n",
    "### 2. NOTEBOOKS FOLDER\n",
    "\n",
    "* Notebooks 1.0 - 1.2: Data collection, cleaning and preparation. Optional if you just want to experiment with the final dataset.\n",
    "\n",
    "* Notebooks 2.0 - 2.1: Fine tuning distilbert with custom dataset and detailed testing with unseen validation dataset, as well as a fresh dataset with state troll tweets from Iran.\n",
    "\n",
    "* Notebook 3.0 - 3.1: Create and test optimised logistic regression and XGB models against datasets used to assess fine tuned Distilbert model.\n",
    "\n",
    "\n",
    "### 3. APP FOLDER\n",
    "\n",
    "* app.py + folders for \"static\" and \"template: simple app for use on a local machine to demonstrate how a state troll tweet detector can be used in deployment. Unfortunately free hosting accounts can't accomodate the disk size required for pytorch and the fine tuned model, so I've not deployed this online. \n",
    "\n",
    "\n",
    "### 4. TROLL_DETECT FOLDER\n",
    "\n",
    "* Fine tuned Distilbert model from Colab notebook2.0. Too big for Github, download [here](https://www.dropbox.com/sh/90h7ymog2oi5yn7/AACTuxmMTcso6aMxSmSiD8AVa) from Dropbox instead.\n",
    "\n",
    "### 5. PKL FOLDER\n",
    "\n",
    "* Pickled logistic regression model from notebook3.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1B: REAL TWEETS COLLECTION, CLEANING AND PREPARATION\n",
    "\n",
    "In this notebook, we'll scrape real tweets using Tweepy. You'll need your own auth keys to run the notebook on your own local machine. All 175 accounts scraped are listed below. I don't recommend running the full list as is, due to well known issues about rate limiting on Twitter's end. You are better off splitting your desired list of real users into smaller chunks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0: SCRAPE TWEETS WITH TWEEPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONSUMER_KEY = os.getenv('CONSUMER_KEY')\n",
    "CONSUMER_SECRET = os.getenv('CONSUMER_SECRET')\n",
    "ACCESS_KEY = os.getenv('ACCESS_KEY')\n",
    "ACCESS_SECRET = os.getenv('ACCESS_SECRET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to scrape tweets and write to csv file\n",
    "\n",
    "def get_tweets(username):\n",
    "    csv_file = open(\"../data/real_tweets.csv\", \"a\")\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "\n",
    "    # Authorization to consumer key and consumer secret\n",
    "    auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "\n",
    "    # Access to user's access key and access secret\n",
    "    auth.set_access_token(ACCESS_KEY, ACCESS_SECRET)\n",
    "\n",
    "    # Calling api\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "    # Get tweets\n",
    "    for tweet in tweepy.Cursor(api.user_timeline, screen_name=username).items():\n",
    "        csv_writer.writerow(\n",
    "            [\n",
    "                tweet.id,\n",
    "                tweet.author.screen_name,\n",
    "                tweet.created_at,\n",
    "                tweet.lang,\n",
    "                tweet.source,\n",
    "                tweet.retweet_count,\n",
    "                tweet.favorited,\n",
    "                tweet.retweeted,\n",
    "                tweet.text\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('nytimes')\n",
    "get_tweets('washingtonpost')\n",
    "get_tweets('Reuters')\n",
    "get_tweets('ChannelNewsAsia')\n",
    "get_tweets('STcom')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('FoxFriendsFirst')\n",
    "get_tweets('TheEconomist')\n",
    "get_tweets('politico')\n",
    "get_tweets('CNN')\n",
    "get_tweets('WSJ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('realDonaldTrump')\n",
    "get_tweets('newtgingrich')\n",
    "get_tweets('RichardGrenell')\n",
    "get_tweets('FrankLuntz')\n",
    "get_tweets('AmbJohnBolton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('JoeBiden')\n",
    "get_tweets('KamalaHarris')\n",
    "get_tweets('SenSanders')\n",
    "get_tweets('PeteButtigieg')\n",
    "get_tweets('AOC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('maggieNYT')\n",
    "get_tweets('JeffreyGoldberg')\n",
    "get_tweets('maddow')\n",
    "get_tweets('jaketapper')\n",
    "get_tweets('ezraklein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('BillKristol')\n",
    "get_tweets('Peggynoonannyc')\n",
    "get_tweets('IngrahamAngle')\n",
    "get_tweets('TuckerCarlson')\n",
    "get_tweets('megynkelly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('CaseyNewton')\n",
    "get_tweets('dandrezner')\n",
    "get_tweets('kevinroose')\n",
    "get_tweets('karaswisher')\n",
    "get_tweets('gtconway3d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('axios')\n",
    "get_tweets('voxdotcom')\n",
    "get_tweets('TheAtlantic')\n",
    "get_tweets('latimes')\n",
    "get_tweets('DMRegister')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('CNBC')\n",
    "get_tweets('guardian')\n",
    "get_tweets('NewYorker')\n",
    "get_tweets('MSNBC')\n",
    "get_tweets('business')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('EricTrump')\n",
    "get_tweets('IvankaTrump')\n",
    "get_tweets('Liz_Cheney')\n",
    "get_tweets('DonaldJTrumpJr')\n",
    "get_tweets('seanhannity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('HillaryClinton')\n",
    "get_tweets('ewarren')\n",
    "get_tweets('NYGovCuomo')\n",
    "get_tweets('AndrewYang')\n",
    "get_tweets('davidaxelrod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('daveweigel')\n",
    "get_tweets('ThePlumLineGS')\n",
    "get_tweets('JamesFallows')\n",
    "get_tweets('morningmoneyben')\n",
    "get_tweets('weijia')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('DineshDSouza')\n",
    "get_tweets('ByronYork')\n",
    "get_tweets('soledadobrien')\n",
    "get_tweets('RonBrownstein')\n",
    "get_tweets('alexwagner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('billmaher')\n",
    "get_tweets('NormOrnstein')\n",
    "get_tweets('jayrosen_nyu')\n",
    "get_tweets('Toure')\n",
    "get_tweets('brhodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('SCMPNews')\n",
    "get_tweets('HongKongFP')\n",
    "get_tweets('ReutersChina')\n",
    "get_tweets('CDT')\n",
    "get_tweets('ChinaRealTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('wongmjane')\n",
    "get_tweets('mranti')\n",
    "get_tweets('prchovanec')\n",
    "get_tweets('BonnieGlaser')\n",
    "get_tweets('niubi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('JKynge')\n",
    "get_tweets('BeijingPalmer')\n",
    "get_tweets('suilee')\n",
    "get_tweets('meifongwriter')\n",
    "get_tweets('PekingMike')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('damienics')\n",
    "get_tweets('GregPoling')\n",
    "get_tweets('yangyang_cheng')\n",
    "get_tweets('limlouisa')\n",
    "get_tweets('vshih2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('BaldingsWorld')\n",
    "get_tweets('klustout')\n",
    "get_tweets('RealSexyCyborg')\n",
    "get_tweets('laurelchor')\n",
    "get_tweets('hebeipangzai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('thewirechina')\n",
    "get_tweets('HongKongFP')\n",
    "get_tweets('ReutersChina')\n",
    "get_tweets('CDT')\n",
    "get_tweets('ChinaRealTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('thewirechina')\n",
    "get_tweets('HongKongFP')\n",
    "get_tweets('ReutersChina')\n",
    "get_tweets('CDT')\n",
    "get_tweets('ChinaRealTime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('joshchin')\n",
    "get_tweets('gillianwong')\n",
    "get_tweets('beijingscribe')\n",
    "get_tweets('stegersaurus')\n",
    "get_tweets('ulywang')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('WeiDuCNA')\n",
    "get_tweets('davidpaulk')\n",
    "get_tweets('dakekang')\n",
    "get_tweets('tmitchpk')\n",
    "get_tweets('sharonchenhm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('SophieMak1')\n",
    "get_tweets('melissakchan')\n",
    "get_tweets('aliceysu')\n",
    "get_tweets('lilkuo')\n",
    "get_tweets('vshih2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('You_Shu_China')\n",
    "get_tweets('jmulvenon')\n",
    "get_tweets('fravel')\n",
    "get_tweets('YuanfenYang')\n",
    "get_tweets('humarisaac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('teamlipei')\n",
    "get_tweets('EmilyZFeng')\n",
    "get_tweets('ByChunHan')\n",
    "get_tweets('JChengWSJ')\n",
    "get_tweets('IlariaMariaSala'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('supchinanews')\n",
    "get_tweets('TechBuzzChina')\n",
    "get_tweets('cnmediaproject')\n",
    "get_tweets('The_ChinaStory')\n",
    "get_tweets('CNStorytellers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('ccni')\n",
    "get_tweets('JiayangFan')\n",
    "get_tweets('CarlMinzner')\n",
    "get_tweets('michaelxpettis')\n",
    "get_tweets('onlyyoontv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('jeromeacohen')\n",
    "get_tweets('lokmantsui')\n",
    "get_tweets('rzhongnotes')\n",
    "get_tweets('vwang3')\n",
    "get_tweets('evadou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('CaiweiC')\n",
    "get_tweets('DSORennie')\n",
    "get_tweets('sophia_yan')\n",
    "get_tweets('wang_maya')\n",
    "get_tweets('kaifulee')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('yananw')\n",
    "get_tweets('DGTam86')\n",
    "get_tweets('ruima')\n",
    "get_tweets('yiqinfu')\n",
    "get_tweets('chenchenzh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('Dali_Yang')\n",
    "get_tweets('Yaqiu')\n",
    "get_tweets('xinwenxiaojie')\n",
    "get_tweets('ericfish85')\n",
    "get_tweets('KaiserKuo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('AbacusNews')\n",
    "get_tweets('MacroPoloChina')\n",
    "get_tweets('ChinaFile')\n",
    "get_tweets('chinaquarterly')\n",
    "get_tweets('LaszloCHP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('XinqiSu')\n",
    "get_tweets('gadyepstein')\n",
    "get_tweets('QiZHAI')\n",
    "get_tweets('Chao_Deng')\n",
    "get_tweets('anthonytao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('DRechts')\n",
    "get_tweets('akaDashan')\n",
    "get_tweets('claydube')\n",
    "get_tweets('S_Rabinovitch')\n",
    "get_tweets('FuDaoge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_tweets('adam_ni')\n",
    "get_tweets('ritacyliao')\n",
    "get_tweets('Junmai1103')\n",
    "get_tweets('JeromeTaylor')\n",
    "get_tweets('austinramzy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_tweets = pd.read_csv(\n",
    "    \"../data/real_tweets.csv\",\n",
    "    names=[\n",
    "        \"tweetid\",\n",
    "        \"user_screen_name\",\n",
    "        \"tweet_time\",\n",
    "        \"tweet_language\",\n",
    "        \"source\",\n",
    "        \"retweet_count\",\n",
    "        \"favorited\",\n",
    "        \"rewteeted\",\n",
    "        \"tweet_text\",\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1: CLEAN + FILTER TWEET TEXT\n",
    "\n",
    "Same cleaning and filtering rules as those for the troll tweets: only English tweets, dropping retweets and tweets with fewer than 3 words after cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning function. adjust according to your use case\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)  # Change 't to 'not'\n",
    "    text = re.sub(r\"(@.*?)[\\s]\", \" \", text)  # Remove @name\n",
    "    text = re.sub(r\"$\\d+\\W+|\\b\\d+\\b|\\W+\\d+$\", \" \", text)  # remove digits\n",
    "    text = re.sub(r\"[^\\w\\s\\#]\", \"\", text)  # remove special characters except hashtags\n",
    "    text = text.strip(\" \")\n",
    "    text = re.sub(\n",
    "        \" +\", \" \", text\n",
    "    ).strip()  # get rid of multiple spaces and replace with a single\n",
    "    return text\n",
    "\n",
    "\n",
    "real_tweets[\"clean_text\"] = real_tweets[\"tweet_text\"].map(lambda text: clean_text(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_tweets['word_count'] = real_tweets['clean_text'].str.count(' ') + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit1 = real_tweets[\"tweet_language\"] == \"en\"\n",
    "crit2 = ~real_tweets[\"tweet_text\"].str.startswith(\"RT @\")\n",
    "crit6 = ~real_tweets[\"tweet_text\"].str.startswith(\"RT@\")\n",
    "crit3 = ~real_tweets[\"clean_text\"].isnull()\n",
    "crit4 = real_tweets[\"clean_text\"] != \"\"\n",
    "crit5 = real_tweets[\"word_count\"] > 3\n",
    "\n",
    "real_tweets = real_tweets[crit1 & crit2 & crit3 & crit4 & crit5 & crit6].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"tweetid\", \"user_screen_name\", \"tweet_text\", \"clean_text\"]\n",
    "\n",
    "real_tweets = real_tweets[cols].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_tweets = real_tweets.rename(\n",
    "    columns={\n",
    "        \"tweetid\": \"tweetid\",\n",
    "        \"user_screen_name\": \"user_display_name\",\n",
    "        \"tweet_text\": \"tweet_text\",\n",
    "        \"clean_text\": \"clean_text\",\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# troll tweets are labelled 1\n",
    "\n",
    "real_tweets[\"troll_or_not\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 SLICE SMALLER SAMPLE OF REAL TWEETS\n",
    "\n",
    "Again, this is to make the fine tuning process more manageable. If you have access to better compute, feel free to run on a bigger slice of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_sample = real_tweets.sample(n=50000, random_state=42, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this dataset is avail in the repo in case you want an even smaller slice\n",
    "# Download here https://github.com/chuachinhon/transformers_state_trolls_cch/blob/master/data/real_50k.csv\n",
    "\n",
    "# real_sample.to_csv('../data/real_50k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
